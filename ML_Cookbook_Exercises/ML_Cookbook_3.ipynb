{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Machine Learning practice problems from book Machine Learning with Python Cookbook by Kyle Gallatin and Chris Albon**"
      ],
      "metadata": {
        "id": "zdpLAn4meCKW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Naive Bayes"
      ],
      "metadata": {
        "id": "I0-pe_fzeD2u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bayes’ theorem is the premier method for understanding the probability of some\n",
        "event, P A ∣ B , given some new information, P B ∣ A , and a prior belief in the\n",
        "probability of the event, P A :\n",
        "P (A ∣ B) = (P (B ∣ A)*P (A) )/ P (B)"
      ],
      "metadata": {
        "id": "TwgTcxDreL_i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training a Classifier for Continuous Features"
      ],
      "metadata": {
        "id": "5_tZH0ZOe7_d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import datasets\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "# Load data\n",
        "iris = datasets.load_iris()\n",
        "features = iris.data\n",
        "target = iris.target\n",
        "# Create Gaussian naive Bayes object\n",
        "classifer = GaussianNB()\n",
        "# Train model\n",
        "model = classifer.fit(features, target)"
      ],
      "metadata": {
        "id": "5CaV7QRaeLi6"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LCOzG1X2d6NS",
        "outputId": "90b977d0-ae8e-454a-ea47-5e52b54d4c82"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1])"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "# Create new observation\n",
        "new_observation = [[ 4, 4, 4, 0.4]]\n",
        "# Predict class\n",
        "model.predict(new_observation)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Gaussian naive Bayes object with prior probabilities of each class\n",
        "clf = GaussianNB(priors=[0.25, 0.25, 0.5])\n",
        "# Train model\n",
        "model = classifer.fit(features, target)"
      ],
      "metadata": {
        "id": "5WPQnIpDfGSt"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training a Classifier for Discrete and Count Features"
      ],
      "metadata": {
        "id": "zoOjMBVYfIfz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "# Create text\n",
        "text_data = np.array(['I love Brazil. Brazil!',\n",
        "'Brazil is best',\n",
        "'Germany beats both'])\n",
        "# Create bag of words\n",
        "count = CountVectorizer()\n",
        "bag_of_words = count.fit_transform(text_data)\n",
        "# Create feature matrix\n",
        "features = bag_of_words.toarray()\n",
        "# Create target vector\n",
        "target = np.array([0,0,1])\n",
        "# Create multinomial naive Bayes object with prior probabilities of each class\n",
        "classifer = MultinomialNB(class_prior=[0.25, 0.5])\n",
        "# Train model\n",
        "model = classifer.fit(features, target)"
      ],
      "metadata": {
        "id": "47uySQDTfKXf"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create new observation\n",
        "new_observation = [[0, 0, 0, 1, 0, 1, 0]]\n",
        "# Predict new observation's class\n",
        "model.predict(new_observation)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uF2PPwdmfmj9",
        "outputId": "75bd7d8d-1041-46f3-d2d9-c9e4a5ae7813"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training a Naive Bayes Classifier for Binary Features"
      ],
      "metadata": {
        "id": "M098YSMRf9Po"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load libraries\n",
        "import numpy as np\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "# Create three binary features\n",
        "features = np.random.randint(2, size=(100, 3))\n",
        "# Create a binary target vector\n",
        "target = np.random.randint(2, size=(100, 1)).ravel()\n",
        "# Create Bernoulli naive Bayes object with prior probabilities of each class\n",
        "classifer = BernoulliNB(class_prior=[0.25, 0.5])\n",
        "# Train model\n",
        "model = classifer.fit(features, target)"
      ],
      "metadata": {
        "id": "Ly_pghjHgA5X"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_uniform_prior = BernoulliNB(class_prior=None, fit_prior=False)"
      ],
      "metadata": {
        "id": "4YE8UpqZgFEe"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Calibrating Predicted Probabilities"
      ],
      "metadata": {
        "id": "CwQ0zsYjgGhR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load libraries\n",
        "from sklearn import datasets\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "# Load data\n",
        "iris = datasets.load_iris()\n",
        "features = iris.data\n",
        "target = iris.target\n",
        "# Create Gaussian naive Bayes object\n",
        "classifer = GaussianNB()\n",
        "# Create calibrated cross-validation with sigmoid calibration\n",
        "classifer_sigmoid = CalibratedClassifierCV(classifer, cv=2, method='sigmoid')\n",
        "# Calibrate probabilities\n",
        "classifer_sigmoid.fit(features, target)\n",
        "# Create new observation\n",
        "new_observation = [[ 2.6, 2.6, 2.6, 0.4]]\n",
        "# View calibrated probabilities\n",
        "classifer_sigmoid.predict_proba(new_observation)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JhvcubFygI69",
        "outputId": "4d3dd394-07f2-41fd-aeff-a417fb9fd3c8"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.31859971, 0.63663451, 0.04476578]])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train a Gaussian naive Bayes then predict class probabilities\n",
        "classifer.fit(features, target).predict_proba(new_observation)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ry_U1hxmgNcH",
        "outputId": "1cb93db1-8a76-48b7-de12-75700ea738c3"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2.31548432e-04, 9.99768128e-01, 3.23532277e-07]])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Clustering"
      ],
      "metadata": {
        "id": "2A-ATvwlgXJv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Clustering Using K-Means\n",
        "\n",
        "K-means clustering is one of the most common clustering techniques. In k-means\n",
        "clustering, the algorithm attempts to group observations into k groups, with each group having roughly equal variance. The number of groups, k, is specified by the\n",
        "user as a hyperparameter. Specifically, in k-means:\n",
        "\n",
        "1. k cluster “center” points are created at random locations.\n",
        "\n",
        "2. For each observation:\n",
        "a. The distance between each observation and the k center points is calculated.\n",
        "b. The observation is assigned to the cluster of the nearest center point.\n",
        "\n",
        "3. The center points are moved to the means (i.e., centers) of their respective\n",
        "clusters.\n",
        "\n",
        "4. Steps 2 and 3 are repeated until no observation changes in cluster membership.\n",
        "\n",
        "At this point the algorithm is considered converged and stops.\n",
        "\n"
      ],
      "metadata": {
        "id": "9pov8IONhCCN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load libraries\n",
        "from sklearn import datasets\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.cluster import KMeans\n",
        "# Load data\n",
        "iris = datasets.load_iris()\n",
        "features = iris.data\n",
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "features_std = scaler.fit_transform(features)\n",
        "# Create k-means object\n",
        "cluster = KMeans(n_clusters=3, random_state=0, n_init=\"auto\")\n",
        "# Train model\n",
        "model = cluster.fit(features_std)"
      ],
      "metadata": {
        "id": "lMYLtDJGhcJa"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# View predicted class\n",
        "model.labels_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fay_28Hihqzk",
        "outputId": "0233d40e-5298-4bcc-b16f-36429cb8cc2e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 2, 2, 2, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 2,\n",
              "       0, 0, 0, 0, 2, 0, 0, 0, 0, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 2, 2, 2, 0, 2, 2, 2,\n",
              "       2, 2, 2, 0, 0, 2, 2, 2, 2, 0, 2, 0, 2, 0, 2, 2, 0, 2, 2, 2, 2, 2,\n",
              "       2, 0, 0, 2, 2, 2, 0, 2, 2, 2, 0, 2, 2, 2, 0, 2, 2, 0], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# View true class\n",
        "iris.target"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bcSUv8uwhwPT",
        "outputId": "45f93071-2414-4dd9-e010-b06211f2cfc1"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create new observation\n",
        "new_observation = [[0.8, 0.8, 0.8, 0.8]]\n",
        "# Predict observation's cluster\n",
        "model.predict(new_observation)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xj-L6Oy2hx6B",
        "outputId": "9b50dd00-e63e-4e18-e60d-bb7d6bda658e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# View cluster centers\n",
        "model.cluster_centers_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xaLxkupfh1OJ",
        "outputId": "5195be43-a4f1-4690-db07-90f44a549c4c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.05021989, -0.88337647,  0.34773781,  0.2815273 ],\n",
              "       [-1.01457897,  0.85326268, -1.30498732, -1.25489349],\n",
              "       [ 1.13597027,  0.08842168,  0.99615451,  1.01752612]])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Speeding Up K-Means Clustering"
      ],
      "metadata": {
        "id": "sF3X_B5_h3eb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load libraries\n",
        "from sklearn import datasets\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.cluster import MiniBatchKMeans\n",
        "# Load data\n",
        "iris = datasets.load_iris()\n",
        "features = iris.data\n",
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "features_std = scaler.fit_transform(features)\n",
        "# Create k-mean object\n",
        "cluster = MiniBatchKMeans(n_clusters=3,\n",
        "                          random_state=0,\n",
        "                          batch_size=100,\n",
        "                          n_init=\"auto\")\n",
        "# Train model\n",
        "model = cluster.fit(features_std)"
      ],
      "metadata": {
        "id": "5IvWJoITh59q"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Clustering Using Mean Shift"
      ],
      "metadata": {
        "id": "QmizKFnZiBtG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load libraries\n",
        "from sklearn import datasets\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.cluster import MeanShift\n",
        "# Load data\n",
        "iris = datasets.load_iris()\n",
        "features = iris.data\n",
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "features_std = scaler.fit_transform(features)\n",
        "# Create mean shift object\n",
        "cluster = MeanShift(n_jobs=-1)\n",
        "# Train model\n",
        "model = cluster.fit(features_std)"
      ],
      "metadata": {
        "id": "76HmLy5PiDiK"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Clustering Using DBSCAN"
      ],
      "metadata": {
        "id": "Od3CYHtTiG2L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load libraries\n",
        "from sklearn import datasets\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.cluster import DBSCAN\n",
        "# Load data\n",
        "iris = datasets.load_iris()\n",
        "features = iris.data\n",
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "features_std = scaler.fit_transform(features)\n",
        "# Create DBSCAN object\n",
        "cluster = DBSCAN(n_jobs=-1)\n",
        "# Train model\n",
        "model = cluster.fit(features_std)"
      ],
      "metadata": {
        "id": "Ro_Vk_zkiIqG"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Show cluster membership\n",
        "model.labels_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jpk_ybmgiM0r",
        "outputId": "aa36a950-47a5-49f6-c7c3-6ebfeddd677f"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, -1, -1,  0,\n",
              "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, -1, -1,\n",
              "        0,  0,  0,  0,  0,  0,  0, -1,  0,  0,  0,  0,  0,  0,  0,  0,  1,\n",
              "        1,  1,  1,  1,  1, -1, -1,  1, -1, -1,  1, -1,  1,  1,  1,  1,  1,\n",
              "       -1,  1,  1,  1, -1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
              "       -1,  1, -1,  1,  1,  1,  1,  1, -1,  1,  1,  1,  1, -1,  1, -1,  1,\n",
              "        1,  1,  1, -1, -1, -1, -1, -1,  1,  1,  1,  1, -1,  1,  1, -1, -1,\n",
              "       -1,  1,  1, -1,  1,  1, -1,  1,  1,  1, -1, -1, -1,  1,  1,  1, -1,\n",
              "       -1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1, -1,  1])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Clustering Using Hierarchical Merging"
      ],
      "metadata": {
        "id": "y7F0Jcx_iPt1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load libraries\n",
        "from sklearn import datasets\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "# Load data\n",
        "iris = datasets.load_iris()\n",
        "features = iris.data\n",
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "features_std = scaler.fit_transform(features)\n",
        "# Create agglomerative clustering object\n",
        "cluster = AgglomerativeClustering(n_clusters=3)\n",
        "# Train model\n",
        "model = cluster.fit(features_std)"
      ],
      "metadata": {
        "id": "Vl7nwhgtiRZq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Show cluster membership\n",
        "model.labels_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8lU7i5a3iTZZ",
        "outputId": "d9b019ef-b06c-4683-efec-ee75c263042b"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, -1, -1,  0,\n",
              "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, -1, -1,\n",
              "        0,  0,  0,  0,  0,  0,  0, -1,  0,  0,  0,  0,  0,  0,  0,  0,  1,\n",
              "        1,  1,  1,  1,  1, -1, -1,  1, -1, -1,  1, -1,  1,  1,  1,  1,  1,\n",
              "       -1,  1,  1,  1, -1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
              "       -1,  1, -1,  1,  1,  1,  1,  1, -1,  1,  1,  1,  1, -1,  1, -1,  1,\n",
              "        1,  1,  1, -1, -1, -1, -1, -1,  1,  1,  1,  1, -1,  1,  1, -1, -1,\n",
              "       -1,  1,  1, -1,  1,  1, -1,  1,  1,  1, -1, -1, -1,  1,  1,  1, -1,\n",
              "       -1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1, -1,  1])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tensors with Pytorch"
      ],
      "metadata": {
        "id": "TOgtUJlfiW8s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load library\n",
        "import torch\n",
        "# Create a vector as a row\n",
        "tensor_row = torch.tensor([1, 2, 3])\n",
        "\n",
        "# Create a vector as a column\n",
        "tensor_column = torch.tensor(\n",
        "                              [\n",
        "                              [1],\n",
        "                              [2],\n",
        "                              [3]\n",
        "                              ]\n",
        "                              )"
      ],
      "metadata": {
        "id": "zO3JtZGSiZRh"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_row"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "06TI39mWisiy",
        "outputId": "99e1440d-24d2-4dfd-f479-394ba6ce3720"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_column"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eZZ2ZtKkim5E",
        "outputId": "d225e5eb-2ac1-4a51-db81-7afcfabcd101"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1],\n",
              "        [2],\n",
              "        [3]])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating a Tensor from NumPy"
      ],
      "metadata": {
        "id": "nmrnySsLixTe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "# Create a NumPy array\n",
        "vector_row = np.array([1, 2, 3])\n",
        "# Create a tensor from a NumPy array\n",
        "tensor_row1 = torch.from_numpy(vector_row)"
      ],
      "metadata": {
        "id": "SbStF8m_i1H2"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_row1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YiULAdp9i5eQ",
        "outputId": "1cddb328-573e-4e18-edb7-7be520b96758"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating a Sparse Tensor"
      ],
      "metadata": {
        "id": "DVJPDL5mi_uz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "import torch\n",
        "# Create a tensor\n",
        "tensor = torch.tensor(\n",
        "[\n",
        "[0, 0],\n",
        "[0, 1],\n",
        "[3, 0]\n",
        "]\n",
        ")\n",
        "# Create a sparse tensor from a regular tensor\n",
        "sparse_tensor = tensor.to_sparse()"
      ],
      "metadata": {
        "id": "KX1ZvEHFjDhO"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(tensor))\n",
        "print(type(sparse_tensor))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rHMeHetsjFcr",
        "outputId": "088e4067-e986-44dc-c001-ceab7551f63e"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Selecting Elements in a Tensor"
      ],
      "metadata": {
        "id": "l_lpQYWLjINo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load library\n",
        "import torch\n",
        "# Create vector tensor\n",
        "vector = torch.tensor([1, 2, 3, 4, 5, 6])\n",
        "# Create matrix tensor\n",
        "matrix = torch.tensor(\n",
        "[\n",
        "[1, 2, 3],\n",
        "[4, 5, 6],\n",
        "[7, 8, 9]\n",
        "]\n",
        ")\n",
        "# Select third element of vector\n",
        "print(vector[2])\n",
        "\n",
        "# Select second row, second column\n",
        "print(matrix[1,1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zUjuMH6JjKvO",
        "outputId": "9a54bbfd-ff6b-447c-fa50-680087169819"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(3)\n",
            "tensor(5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Select all elements of a vector\n",
        "print(vector[:])\n",
        "\n",
        "# Select everything up to and including the third element\n",
        "print(vector[:3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IR3Y-q44jX8z",
        "outputId": "750ad260-594c-4d59-da89-b2dce415bd79"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 2, 3, 4, 5, 6])\n",
            "tensor([1, 2, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Select the first two rows and all columns of a matrix\n",
        "matrix[:2,:]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KlxCy0McjgZJ",
        "outputId": "d2ce5d02-7122-48cd-a449-335c5d7dfaa8"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 2, 3],\n",
              "        [4, 5, 6]])"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Select all rows and the second column\n",
        "matrix[:,1:2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "79MI3dMRjh-d",
        "outputId": "3e6052c0-fb21-47a1-f8f7-d1408e209af8"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[2],\n",
              "        [5],\n",
              "        [8]])"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Select the last element\n",
        "vector[-1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tOyguyQIjv0J",
        "outputId": "59acb5f3-a273-41d4-ed3f-8b120f7165a8"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(6)"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vector.flip(dims=(-1,))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xk2yMw-cjzbx",
        "outputId": "49b8fae2-5fc5-49c7-9147-efc5b2f799e8"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([6, 5, 4, 3, 2, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "tensor = torch.tensor([[1,2,3], [1,2,3]])\n",
        "# Get the shape of the tensor\n",
        "tensor.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "StEo7_Bqj48v",
        "outputId": "82a66564-2d93-416b-ea25-448fc6c5b596"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the data type of items in the tensor\n",
        "tensor.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eZL7IO_uj-CI",
        "outputId": "8766ffdd-51d0-46e6-9d2d-d5ca22577ebd"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.int64"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the layout of the tensor\n",
        "tensor.layout"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "We1qjhObj_mg",
        "outputId": "776e40e3-9c50-4cb9-92b2-be93194b2843"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.strided"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the device being used by the tensor\n",
        "tensor.device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XZAj5mH4kA_E",
        "outputId": "2a5e0a3e-022a-43bb-8cea-9ac6cde97d12"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Applying Operations to Elements"
      ],
      "metadata": {
        "id": "VIjKU6eTkK2G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a tensor\n",
        "tensor = torch.tensor([1, 2, 3])\n",
        "# Broadcast an arithmetic operation to all elements in a tensor\n",
        "tensor * 100"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C5sfW6mRkOWR",
        "outputId": "d626a903-12c7-4063-e157-0bae0bd47c39"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([100, 200, 300])"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a tensor\n",
        "torch.tensor([1,2,3])\n",
        "# Find the largest value\n",
        "tensor.max()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YgOrfzXPkRL6",
        "outputId": "36a157b5-8a71-41f2-df3c-a179c3449379"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(3)"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the smallest value\n",
        "tensor.min()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EdFvb3OjkS6V",
        "outputId": "a4d3510a-3a2e-4957-ca0a-388c2c8207d3"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1)"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create 4x3 tensor\n",
        "tensor = torch.tensor([[1, 2, 3],\n",
        "[4, 5, 6],\n",
        "[7, 8, 9],\n",
        "[10, 11, 12]])\n",
        "# Reshape tensor into 2x6 tensor\n",
        "tensor.reshape(2, 6)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zGdN0jvdkXTU",
        "outputId": "8938f3c5-dfda-4e4a-ee93-46b58f6cbe90"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1,  2,  3,  4,  5,  6],\n",
              "        [ 7,  8,  9, 10, 11, 12]])"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a two-dimensional tensor\n",
        "tensor = torch.tensor([[[1,2,3]]])\n",
        "# Transpose it\n",
        "tensor.mT"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T3Lfjo1akaJO",
        "outputId": "002cf5c3-fcb2-49eb-c76c-2a6d3cd3d492"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[1],\n",
              "         [2],\n",
              "         [3]]])"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "An additional way to transpose PyTorch tensors of any shape is to use the permute\n",
        "method:\n",
        "\"\"\"\n",
        "tensor.permute(*torch.arange(tensor.ndim - 1, -1, -1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RBV0fWdxkcx3",
        "outputId": "2b92122a-22b5-41b9-d5f8-2d6ea404fa97"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[1]],\n",
              "\n",
              "        [[2]],\n",
              "\n",
              "        [[3]]])"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor = torch.tensor([[1, 2, 3],\n",
        "[4, 5, 6],\n",
        "[7, 8, 9]])\n",
        "# Flatten tensor\n",
        "tensor.flatten()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hGy3h5BtkpKs",
        "outputId": "a138f881-9b63-48c6-abaf-058a221d5a1c"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 2, 3, 4, 5, 6, 7, 8, 9])"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_1 = torch.tensor([1, 2, 3])\n",
        "# Create another tensor\n",
        "tensor_2 = torch.tensor([4, 5, 6])\n",
        "# Multiply the two tensors\n",
        "tensor_1 * tensor_2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NHJz3llokutS",
        "outputId": "9b3ce123-53b0-4fb6-c536-b32361df4b70"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 4, 10, 18])"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_1+tensor_2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OEwsz6KokzPO",
        "outputId": "7514c7b9-7e92-457f-9e97-23aedbabb919"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([5, 7, 9])"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_1-tensor_2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7KSMaZHDk1Uk",
        "outputId": "913bef77-c94b-4f16-dbcd-74740a8e5f9a"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-3, -3, -3])"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_1/tensor_2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iv2hHC3Pk3ZT",
        "outputId": "8fc1ded1-067f-4686-f570-06fab0d266f0"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.2500, 0.4000, 0.5000])"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create one tensor\n",
        "tensor_1 = torch.tensor([1, 2, 3])\n",
        "# Create another tensor\n",
        "tensor_2 = torch.tensor([4, 5, 6])\n",
        "# Calculate the dot product of the two tensors\n",
        "tensor_1.dot(tensor_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F5ZVX3USksCS",
        "outputId": "a48c13ec-45f5-4ed7-83b5-40db7c1c8ae8"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(32)"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Neural Networks"
      ],
      "metadata": {
        "id": "nEeKTqMNk50Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Using Autograd with PyTorch\n",
        "# Import libraries\n",
        "import torch\n",
        "# Create a torch tensor that requires gradients\n",
        "t = torch.tensor([1.0, 2.0, 3.0], requires_grad=True)\n",
        "# Perform a tensor operation simulating \"forward propagation\"\n",
        "tensor_sum = t.sum()\n",
        "# Perform back propagation\n",
        "tensor_sum.backward()\n",
        "# View the gradients\n",
        "t.grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ZnOhnoqlncV",
        "outputId": "c939c59d-55aa-41c6-ff45-e49f6112c44a"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1., 1., 1.])"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessing Data for Neural Networks\n",
        "from sklearn import preprocessing\n",
        "import numpy as np\n",
        "# Create feature\n",
        "features = np.array([[-100.1, 3240.1],\n",
        "                    [-200.2, -234.1],\n",
        "                    [5000.5, 150.1],\n",
        "                    [6000.6, -125.1],\n",
        "                    [9000.9, -673.1]])\n",
        "# Create scaler\n",
        "scaler = preprocessing.StandardScaler()\n",
        "# Convert to a tensor\n",
        "features_standardized_tensor = torch.from_numpy(features)\n",
        "# Show features\n",
        "features_standardized_tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sxApm-xOl44m",
        "outputId": "3bf87f03-7045-4414-9e7f-79102e23d5ae"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-100.1000, 3240.1000],\n",
              "        [-200.2000, -234.1000],\n",
              "        [5000.5000,  150.1000],\n",
              "        [6000.6000, -125.1000],\n",
              "        [9000.9000, -673.1000]], dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create features\n",
        "torch_features = torch.tensor([[-100.1, 3240.1],\n",
        "[-200.2, -234.1],\n",
        "[5000.5, 150.1],\n",
        "[6000.6, -125.1],\n",
        "[9000.9, -673.1]], requires_grad=True)\n",
        "# Compute the mean and standard deviation\n",
        "mean = torch_features.mean(0, keepdim=True)\n",
        "standard_deviation = torch_features.std(0, unbiased=False, keepdim=True)\n",
        "# Standardize the features using the mean and standard deviation\n",
        "torch_features_standardized = torch_features - mean\n",
        "torch_features_standardized /= standard_deviation\n",
        "# Show standardized features\n",
        "torch_features_standardized"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yxAC7RjUmEYm",
        "outputId": "994653d4-9f2e-4f73-ac8d-5101891c0a1a"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-1.1254,  1.9643],\n",
              "        [-1.1533, -0.5007],\n",
              "        [ 0.2953, -0.2281],\n",
              "        [ 0.5739, -0.4234],\n",
              "        [ 1.4096, -0.8122]], grad_fn=<DivBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Designing a Neural Network"
      ],
      "metadata": {
        "id": "Psd0h1VUmHeL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "# Define a neural network\n",
        "class SimpleNeuralNet(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(SimpleNeuralNet, self).__init__()\n",
        "    self.fc1 = nn.Linear(10, 16)\n",
        "    self.fc2 = nn.Linear(16, 16)\n",
        "    self.fc3 = nn.Linear(16, 1)\n",
        "  def forward(self, x):\n",
        "    x = nn.functional.relu(self.fc1(x))\n",
        "    x = nn.functional.relu(self.fc2(x))\n",
        "    x = nn.functional.sigmoid(self.fc3(x))\n",
        "    return x\n",
        "# Initialize the neural network\n",
        "network = SimpleNeuralNet()\n",
        "# Define loss function, optimizer\n",
        "loss_criterion = nn.BCELoss()\n",
        "optimizer = torch.optim.RMSprop(network.parameters())\n",
        "# Show the network\n",
        "network"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ItUlvImmKFR",
        "outputId": "690189ad-9a8e-45c3-a869-565dc7667b56"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SimpleNeuralNet(\n",
              "  (fc1): Linear(in_features=10, out_features=16, bias=True)\n",
              "  (fc2): Linear(in_features=16, out_features=16, bias=True)\n",
              "  (fc3): Linear(in_features=16, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "import torch\n",
        "# Define a neural network using `Sequential`\n",
        "class SimpleNeuralNet(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(SimpleNeuralNet, self).__init__()\n",
        "    self.sequential = torch.nn.Sequential(\n",
        "    torch.nn.Linear(10, 16),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Linear(16,16),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Linear(16, 1),\n",
        "    torch.nn.Sigmoid()\n",
        "    )\n",
        "  def forward(self, x):\n",
        "    x = self.sequential(x)\n",
        "    return x\n",
        "# Instantiate and view the network\n",
        "SimpleNeuralNet()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CJ8B3PwZmXrS",
        "outputId": "ccf16bdc-e7c5-4431-c1ad-462793691293"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SimpleNeuralNet(\n",
              "  (sequential): Sequential(\n",
              "    (0): Linear(in_features=10, out_features=16, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=16, out_features=16, bias=True)\n",
              "    (3): ReLU()\n",
              "    (4): Linear(in_features=16, out_features=1, bias=True)\n",
              "    (5): Sigmoid()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training a Binary Classifier"
      ],
      "metadata": {
        "id": "OtHIAfUOmiAr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from torch.optim import RMSprop\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "# Create training and test sets\n",
        "features, target = make_classification(n_classes=2,\n",
        "                                       n_features=10,\n",
        "                                        n_samples=1000)\n",
        "features_train, features_test, target_train, target_test = train_test_split(\n",
        "features, target, test_size=0.1, random_state=1)\n",
        "# Set random seed\n",
        "torch.manual_seed(0)\n",
        "np.random.seed(0)\n",
        "# Convert data to PyTorch tensors\n",
        "x_train = torch.from_numpy(features_train).float()\n",
        "y_train = torch.from_numpy(target_train).float().view(-1, 1)\n",
        "x_test = torch.from_numpy(features_test).float()\n",
        "y_test = torch.from_numpy(target_test).float().view(-1, 1)\n",
        "\n",
        "# Define a neural network using `Sequential`\n",
        "class SimpleNeuralNet(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(SimpleNeuralNet, self).__init__()\n",
        "    self.sequential = torch.nn.Sequential(\n",
        "    torch.nn.Linear(10, 16),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Linear(16,16),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Linear(16, 1),\n",
        "    torch.nn.Sigmoid()\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.sequential(x)\n",
        "    return x\n",
        "\n",
        "# Initialize neural network\n",
        "network = SimpleNeuralNet()\n",
        "# Define loss function, optimizer\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = RMSprop(network.parameters())\n",
        "# Define data loader\n",
        "train_data = TensorDataset(x_train, y_train)\n",
        "train_loader = DataLoader(train_data, batch_size=100, shuffle=True)\n",
        "# Compile the model using torch 2.0's optimizer\n",
        "network = torch.compile(network)\n",
        "# Train neural network\n",
        "epochs = 3\n",
        "for epoch in range(epochs):\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "      optimizer.zero_grad()\n",
        "      output = network(data)\n",
        "      loss = criterion(output, target)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "print(\"Epoch:\", epoch+1, \"\\tLoss:\", loss.item())\n",
        "# Evaluate neural network\n",
        "with torch.no_grad():\n",
        "  output = network(x_test)\n",
        "  test_loss = criterion(output, y_test)\n",
        "  test_accuracy = (output.round() == y_test).float().mean()\n",
        "  print(\"Test Loss:\", test_loss.item(), \"\\tTest Accuracy:\",test_accuracy.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TNXdoBldmlWh",
        "outputId": "21cc68f3-4e5d-4433-d307-7c5f656bf184"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No CUDA runtime is found, using CUDA_HOME='/usr/local/cuda'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 3 \tLoss: 0.03935524821281433\n",
            "Test Loss: 0.06877756863832474 \tTest Accuracy: 0.9700000286102295\n"
          ]
        }
      ]
    }
  ]
}